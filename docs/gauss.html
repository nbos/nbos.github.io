<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Encoding Numbers with Gaussians</title>
     <link rel="icon" type="image/svg+xml" href="res/images/tess.svg">
    <link rel="stylesheet" href="./css/default.css">
    <link rel="stylesheet" href="./css/syntax.css">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <header>
      <div class="logo">
        <a href="./">nbos.ca</a>
      </div>
      <nav>
        <a href="./">Posts</a>
        <a href="./hackage.html">Hackage</a>
        <a href="./contact.html">Contact</a>
      </nav>
    </header>

    <main role="main">
      <h1>Encoding Numbers with Gaussians</h1>
      <article>
  <section class="header">
    Posted on October 17, 2025
    
    by Nathaniel Bos
    
  </section>
  <section>
    <p><a href="arith.html">Arithmetic codes</a> are pretty useful for compression.</p>
<p>There are a number of implementations available online, typically
employing the equivalent of a <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical
distribution</a>
over a finite domain. For example, using a probability table over the
alphabet comensurate with common English text, each letter gets a
section of the unit interval proportional to its frequency:</p>
<p><img src="res/gauss/frequency-bars.svg" /></p>
<p><img src="res/gauss/alphabet.svg" /></p>
<p>But any probability distribution with a well defined <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Quantile_function">quantile
function</a> could be used
for arithmetic coding, even on infinite domains. For instance, a
<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Normal_distribution">Gaussian</a> prior over
integers could be used to compress whole numbers:</p>
<p><img src="res/gauss/gauss-pdf.svg" /></p>
<p><img src="res/gauss/gauss-cdf.svg" /></p>
<p>Each integer <span class="math inline">\(i \in \mathbb{Z}\)</span> is assigned the probability mass
contained within the interval <span class="math inline">\(i \pm 0.5\)</span> on the Gaussian of choice.</p>
<h2 id="viability">Viability</h2>
<h3 id="pdf-as-a-estimator-for-probability">PDF as a Estimator for Probability</h3>
<p>The code length achievable by an arithmetic encoder is within two bits
of the information content of the encoded message, which is the sum of
the individual information content of the constituent symbols. The
information content of a symbol is inversely related to its probability:</p>
<p><span class="math display">\[I(x) = -\log P(x)\]</span></p>
<p>The probability we assign each integer is the probability mass within
the bounds <span class="math inline">\(x \pm 0.5\)</span> of the <span class="math inline">\(PDF\)</span> (the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Probability_density_function">probability density
funtcion</a>,
pictured above). This is computed as</p>
<p><span class="math display">\[\begin{align}P(x) &amp;= CDF(x)|_{x-0.5}^{x+0.5}\\[6pt]
	&amp;= CDF(x+0.5) - CDF(x-0.5)\end{align}\]</span></p>
<p>in terms of the Gaussian <span class="math inline">\(CDF\)</span> (the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">cummulative distribution
function</a>),
which, for a normal <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span> is equal to:</p>
<p><span class="math display">\[CDF(x) = \frac {1}{2}\left[1+\operatorname {erf} \left({\frac {x-\mu
}{\sigma {\sqrt {2}}}}\right)\right]\]</span></p>
<p>which is expressed in terms of the non-elementary, sigmoid, <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Error_function">error
function</a> “erf” which
doesn’t factor or reduce well enough to be useful going further.</p>
<p>Conveniently, however, the <span class="math inline">\(PDF\)</span> already approximates the
<span class="math inline">\(CDF(x)|_{x-0.5}^{x+0.5}\)</span> on grounds that the <span class="math inline">\(CDF\)</span> is the integral of
the <span class="math inline">\(PDF\)</span>:</p>
<p><span class="math display">\[PDF(x) = \lim_{h\to 0} \frac{CDF(x)|_{x-h/2}^{x+h/2}}{h}\]</span></p>
<p>which is just a statement of the fundamental theorem of
calculus. Practically speaking, this means the <span class="math inline">\(PDF\)</span> approximates the
interval-<span class="math inline">\(CDF\)</span>, especially when the variance is at least 1 (here <span class="math inline">\(\mu =
0, \sigma = 1\)</span>):</p>
<p><img src="res/gauss/ftc0.svg" /></p>
<p>and as the variance approaches 0, our probability function flattens
relative to the <span class="math inline">\(PDF\)</span> (here <span class="math inline">\(\sigma \in \{ 0.8^i\)</span> | <span class="math inline">\(i \in \{0,1,2,...\} \}\)</span>
and both axes are scaled to keep the <span class="math inline">\(PDF\)</span> at the same place):</p>
<p><img src="res/gauss/ftc1-0.svg" /></p>
<p>with sigmoid-shaped steps, where the <span class="math inline">\(\pm 0.5\)</span> interval crosses into and
out of the actual <span class="math inline">\(PDF\)</span>:</p>
<p><img src="res/gauss/ftc1-1.svg" /></p>
<p>meaning that either <span class="math inline">\(PDF\)</span> is a good estimator for
<span class="math inline">\(CDF(x)|_{x-0.5}^{x+0.5}\)</span> when <span class="math inline">\(\sigma \geq 1\)</span> or it underestimates the
probability in the tails (even beyond the sigmoid steps) when <span class="math inline">\(\sigma &lt;
1\)</span>. In either case I argue it works as a good “worst-case”.</p>
<p>This is convenient because the <span class="math inline">\(PDF\)</span> doesn’t contain special functions:</p>
<p><span class="math display">\[PDF(x) = \frac{1}{\sqrt {2\pi \sigma ^{2}}}e^{-{\frac {(x-\mu
)^{2}}{2\sigma ^{2}}}}\]</span></p>
<p>We use the <span class="math inline">\(PDF\)</span> to explore the information content of different data
sets w.r.t. their MLE (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood
estimator</a>),
i.e. the Gaussian with mean and variance equal to the mean and variance
of the data.</p>
<h3 id="re-parametrization-of-gaussian-mles">Re-parametrization of Gaussian MLE’s</h3>
<p>The Gaussian MLE of a set of <span class="math inline">\(n\)</span> values <span class="math inline">\(\{x_0, x_1, x_2, ...\}\)</span> has
parameters:</p>
<p><span class="math display">\[\mu = \frac{\sum x}{n} ~~~~~~~~~~~~ \sigma^2 = \frac{\sum (x - \mu)^2}{n}\]</span></p>
<p>Another formulation of variance (which also happens to be the more
numerically stable) is:</p>
<p><span class="math display">\[\sigma^2 = \frac{\sum x^2}{n} - \frac{(\sum x)^2}{n^2}\]</span></p>
<p>or simply:</p>
<p><span class="math display">\[\mu = \frac{s_1}{s_0} ~~~~~~~~~~~~ \sigma^2 = \frac{s_2}{s_0} -
\frac{(s_1)^2}{(s_0)^2}\]</span></p>
<p>where the only parameters are sums of the values raised to a power:</p>
<p><span class="math display">\[s_i = \sum{x^i} ~~~~~~~~~~~~ i \in \{0,1,2\}\]</span></p>
<h3 id="modeling-the-information-of-data-sets">Modeling the Information of Data Sets</h3>
<p>With this formulation we can model the probability density at the
outlier by setting the majority at <span class="math inline">\(0\)</span> and the outlier at <span class="math inline">\(1\)</span> (by
invariance, this is representative of any outlier case modulo a constant
factor):</p>
<p><span class="math display">\[\begin{array}{|l|c|c|c|}
\hline
\text{Population} &amp; s_0 &amp; s_1 &amp; s_2 \\
\hline
\{0,1\} &amp; 2 &amp; 1 &amp; 1 \\
\hline
\{0,0,1\} &amp; 3 &amp; 1 &amp; 1 \\
\hline
\{0,0,0,1\} &amp; 4 &amp; 1 &amp; 1 \\
\hline
\{0,0,...,0,1\} &amp; n &amp; 1 &amp; 1 \\
\hline
\end{array}\]</span></p>
<p>Then we have <span class="math inline">\(s_1 = s_2 = 1\)</span>. We substitute <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> in the
PDF to get a function of <span class="math inline">\(n\)</span>:</p>
<p><span class="math display">\[\begin{align}
	\mathrm{pdf}(x) 
	&amp;= \frac {1}{\sqrt {2\pi \sigma^{2}}}e^{-{\frac {(x-\mu )^{2}}{2\sigma ^{2}}}}\\ 
	\mathrm{pdf}(1) 
	&amp;= \frac{1}{\sqrt {\frac{2\pi}{n} - \frac{2\pi}{n^2}}}e^{-\frac{(n-1)^2}{2n-2}} 
\end{align}\]</span></p>
<p>Which looks like</p>
<p><img src="res/gauss/pdf1.svg" /></p>
<p>which drops pretty quickly (exponentially quickly), but code length only grows
in one over the logarithm of the probability so:</p>
<p><img src="res/gauss/neglnpdf1.svg" /></p>
<p>Which is a pretty unambiguous <span class="math inline">\(0.5n\)</span> towards infinity.</p>
<p>So it looks like the code length of the outlier of a Gaussian only grows
in <span class="math inline">\(O(n)\)</span> of the size of the data set, which is only as bad as the
performance of the uniform distribution of fixed-length codes.</p>
<p>Now, a full account of the performance of the distribution also has to
take into account the code lengths of non-outliers, although we only
expect their likelihood to grow with increasing <span class="math inline">\(n\)</span> compared to the
outlier. For completeness, computing the sum of code lengths using
proper probability intervals (not density) on the CDF, with bin size
<span class="math inline">\(\pm 0.5\)</span> around integers, in base 2, we show the total code length also
achieves linear size w.r.t. <span class="math inline">\(n\)</span> in this outlier “worst case”:</p>
<p><img src="res/gauss/outliercasecodelength.svg" /></p>
<h2 id="an-abstract-arithmetic-coding-interface">An Abstract Arithmetic Coding Interface</h2>
<p>An implementation of arithmetic coding that works with <em>any</em> model is
more abstract than what you typically find online. Here is my
implementation in Rust:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/nbos/cont-arith-code">Source (GitHub)</a></li>
<li><a href="res/doc/cont_arith_code/index.html">Documentation</a></li>
</ul>
<p>Traits are defined for a “model” that emits “distributions” which are
repeatedly truncated at cumulative probabilites <span class="math inline">\(\in (0,1)\)</span> until it
resolves to a specific symbol <span class="math inline">\(s\)</span><code>:i64</code> which is fed back to the
“model”, updating it, before requesting the next “distribution”.</p>
<p>Through defining a limited interface:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode rust"><code class="sourceCode rust"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> Index <span class="op">=</span> <span class="dt">i64</span><span class="op">;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">pub</span> <span class="kw">trait</span> Model<span class="op">&lt;</span>T<span class="op">&gt;</span> <span class="op">{</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> next_distr(<span class="op">&amp;</span><span class="kw">mut</span> <span class="kw">self</span>) <span class="op">-&gt;</span> <span class="dt">Box</span><span class="op">&lt;</span><span class="kw">dyn</span> UnivariateDistribution<span class="op">&gt;;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> push(<span class="op">&amp;</span><span class="kw">mut</span> <span class="kw">self</span><span class="op">,</span> s<span class="op">:</span> <span class="bu">Index</span>) <span class="op">-&gt;</span> <span class="dt">Option</span><span class="op">&lt;</span>T<span class="op">&gt;;</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode rust"><code class="sourceCode rust"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">pub</span> <span class="kw">trait</span> UnivariateDistribution <span class="op">{</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> truncated(<span class="op">&amp;</span><span class="kw">self</span>) <span class="op">-&gt;</span> <span class="dt">Box</span><span class="op">&lt;</span><span class="kw">dyn</span> TruncatedDistribution<span class="op">&gt;;</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode rust"><code class="sourceCode rust"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">pub</span> <span class="kw">trait</span> TruncatedDistribution <span class="op">{</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> quantile(<span class="op">&amp;</span><span class="kw">self</span><span class="op">,</span> cp<span class="op">:</span> <span class="dt">f64</span>) <span class="op">-&gt;</span> (<span class="bu">Index</span><span class="op">,</span> <span class="dt">f64</span>)<span class="op">;</span> <span class="co">// returns (s, s_rem)</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> truncate(<span class="op">&amp;</span><span class="kw">mut</span> <span class="kw">self</span><span class="op">,</span> cp<span class="op">:</span> <span class="dt">f64</span><span class="op">,</span> s<span class="op">:</span> <span class="bu">Index</span><span class="op">,</span> s_rem<span class="op">:</span> <span class="dt">f64</span><span class="op">,</span> bit<span class="op">:</span> <span class="dt">bool</span>)<span class="op">;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> lo(<span class="op">&amp;</span><span class="kw">self</span>) <span class="op">-&gt;</span> <span class="bu">Index</span><span class="op">;</span> <span class="co">// symbol the lower-bound is in</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> hi(<span class="op">&amp;</span><span class="kw">self</span>) <span class="op">-&gt;</span> <span class="bu">Index</span><span class="op">;</span> <span class="co">// symbol the upper-bound is in</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> is_resolved(<span class="op">&amp;</span><span class="kw">self</span>) <span class="op">-&gt;</span> <span class="dt">bool</span> <span class="op">{</span> <span class="kw">self</span><span class="op">.</span>lo() <span class="op">==</span> <span class="kw">self</span><span class="op">.</span>hi() <span class="op">}</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>the algorithm handles the composition (i.e. nesting) of distributions in
the code-space, with interfaces for serialization and de-serialization
of values.</p>
<p>An
<a href="res/doc/cont_arith_code/distribution/categorical/struct.Categorical.html">implementation</a>
for categorical distributions is defined for a typical use-case of
arithmetic coding.</p>
<h2 id="gaussian-implementation">Gaussian Implementation</h2>
<h3 id="tackling-numerical-instability">Tackling Numerical Instability</h3>
<p>The quantile function for Gaussians is continuous, one-to-one, monotone
and has finite value everywhere except at <span class="math inline">\(0 \mapsto -\infty\)</span> and <span class="math inline">\(1
\mapsto \infty\)</span>.</p>
<p><img src="res/gauss/cdfquantile.svg" /></p>
<p>For our application, what’s important is that <em>repeatedly splitting</em> in
half an interval of the probability mass down to any symbol to encode
happens with <em>constant progress</em> (i.e. the middle of any interval cannot
be equal to either boundaries) and no overflow to any infinity. This
reflects on the CDF and quantile by requiring the following: any two
bounds <span class="math inline">\(a,b\)</span> such that <span class="math inline">\(0&lt;a&lt;b&lt;1\)</span> and where both bounds are not already
within the bounds of a symbol, then the middle point <code>quantile(cdf(a) + 0.5*(cdf(b) - cdf(a)))</code> must be strictly greater than <code>a</code> and strictly
less than <code>b</code>. If it is not, encoding becomes impossible.</p>
<p>An easy measure to ensure progress might be to fall back to <em>linear</em>
interpolation whenever the call to the quantile function runs out of
precision, assuming local linearity. While this is a reasonable
approximation in the central bulk of the distribution, it fails in the
tails.</p>
<p>To see why, consider the PDF and its derivative:</p>
<p><img src="res/gauss/pdfdiff.svg" /></p>
<p>While both flatten out at the tails, for any given interval in the
tails, the relative difference becomes greater the further away you move
from the center. To see this, normalize the (absolute) derivative to the
value of the function:</p>
<p><img src="res/gauss/pdfdiffnorm.svg" /></p>
<p>That is, the tails may be flat in absolute terms, but they become
steeper relative to themselves the further away you go. Another way to
demonstrate this is by blowing up the PDF at different scales (here,
successive factors of 10):</p>
<p><img src="res/gauss/pdfscales.svg" /></p>
<p>which makes it more clear why we cannot rely on linear interpolations in
the tails. We are forced to find an analytic or at least numeric
solution that is more faithful to the distribution.</p>
<h3 id="tackling-numerical-instability-for-real">Tackling Numerical Instability (for real)</h3>
<p>Like is usually the case in probability, the solution to numerical
instability is found in the
<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Log_probability">log-domain</a>. This gives
us two analogous functions for the cumulative probability with more
manageable shapes:</p>
<p><img src="res/gauss/logcdfquantileexp.svg" /></p>
<p>Furthermore, we can model all right tail calculations by using the
left’s and avoid all asymptotes by exploiting the symmetry of the
Gaussian PDF. This leaves us with two almost linear curves.</p>
<p>Fortunately, we are not the first to reach this point of the
journey. SciPy has well documented and precise polynomial approximations
of the log-CDF
<a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.log_ndtr.html"><code>log_ndtr</code></a>
(<a target="_blank" rel="noopener" href="https://github.com/scipy/scipy/blob/ab84560b96cf5816be0015b0ee3a41cef708f675/scipy/special/xsf/stats.h#L84">source</a>)
and quantile-exp
<a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.ndtri_exp.html"><code>ndtri_exp</code></a>
(<a target="_blank" rel="noopener" href="https://github.com/scipy/scipy/blob/ab84560b96cf5816be0015b0ee3a41cef708f675/scipy/special/_ndtri_exp.pxd#L163">source</a>). This
affords us the precise interpolations on the probability mass of the
Gaussian we require, at least for now.</p>
<h2 id="examples">Examples</h2>
<p>For the examples below, <em>information content</em> is calculated as the sum
of the <span class="math inline">\(\log_2\)</span>-probabilities of each integer in the distribution. The
<em>expected code length</em> is that value rounded up. <em>Code length</em> is the
empirical result. All codes decode back to the encoded values.</p>
<h3 id="degenerate-case">Degenerate Case</h3>
<p>Integer sets with a single value produce empty codes:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>Set: [<span class="dv">0</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>Model: Gaussian { μ: <span class="dv">0</span>, σ: <span class="dv">0</span> } (<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>Information Content: <span class="dv">0</span> bits</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>Expected code length: <span class="dv">0</span> bits</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>Code: <span class="st">''</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>Code length: <span class="dv">0</span> bits</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>Analysis: <span class="op">+</span><span class="dv">0</span> bits (<span class="op">+</span><span class="fl">0.0</span><span class="op">%</span>) compared to expected</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>Decoding successful</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>Set: [<span class="dv">1</span>]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>Model: Gaussian { μ: <span class="dv">1</span>, σ: <span class="dv">0</span> } (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>Information Content: <span class="dv">0</span> bits</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>Expected code length: <span class="dv">0</span> bits</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>Code: <span class="st">''</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>Code length: <span class="dv">0</span> bits</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>Analysis: <span class="op">+</span><span class="dv">0</span> bits (<span class="op">+</span><span class="fl">0.0</span><span class="op">%</span>) compared to expected</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>Decoding successful</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>Set: [<span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>]</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>Model: Gaussian { μ: <span class="dv">8</span>, σ: <span class="dv">0</span> } (<span class="dv">12</span>, <span class="dv">96</span>, <span class="dv">768</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>Information Content: <span class="dv">0</span> bits</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>Expected code length: <span class="dv">0</span> bits</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>Code: <span class="st">''</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>Code length: <span class="dv">0</span> bits</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>Analysis: <span class="op">+</span><span class="dv">0</span> bits (<span class="op">+</span><span class="fl">0.0</span><span class="op">%</span>) compared to expected</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>Decoding successful</span></code></pre></div>
<h3 id="small-sets">Small Sets</h3>
<p>Small symmetric sets produce consistently optimal codes:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>Set: [<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>Model: Gaussian { μ: <span class="dv">0</span>, σ: <span class="dv">1</span> } (<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>Information Content: <span class="fl">4.0970591008090445</span> bits</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>Expected code length: <span class="dv">5</span> bits</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>Information Contributions (bits): [<span class="fl">2.05</span>, <span class="fl">2.05</span>]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>Code: <span class="st">'01010'</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>Code length: <span class="dv">5</span> bits</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>Analysis: <span class="op">+</span><span class="dv">0</span> bits (<span class="op">+</span><span class="fl">0.0</span><span class="op">%</span>) compared to expected</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>Decoding successful</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>Set: [<span class="op">-</span><span class="dv">1234</span>, <span class="dv">1234</span>]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>Model: Gaussian { μ: <span class="dv">0</span>, σ: <span class="dv">1234</span> } (<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">3045512</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>Information Content: <span class="fl">24.632444528661186</span> bits</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>Expected code length: <span class="dv">25</span> bits</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>Information Contributions (bits): [<span class="fl">12.32</span>, <span class="fl">12.32</span>]</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>Code: <span class="st">'0010100010100110000100000'</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>Code length: <span class="dv">25</span> bits</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>Analysis: <span class="op">+</span><span class="dv">0</span> bits (<span class="op">+</span><span class="fl">0.0</span><span class="op">%</span>) compared to expected</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>Decoding successful</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>Set: [<span class="dv">1</span>, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>Model: Gaussian { μ: <span class="dv">0</span>, σ: <span class="fl">0.816496580927726</span> } (<span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>Information Content: <span class="fl">5.274689097597744</span> bits</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>Expected code length: <span class="dv">6</span> bits</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>Information Contributions (bits): [<span class="fl">2.08</span>, <span class="fl">1.12</span>, <span class="fl">2.08</span>]</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>Code: <span class="st">'111000'</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>Code length: <span class="dv">6</span> bits</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>Analysis: <span class="op">+</span><span class="dv">0</span> bits (<span class="op">+</span><span class="fl">0.0</span><span class="op">%</span>) compared to expected</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>Decoding successful</span></code></pre></div>
<h3 id="outlier-case">Outlier Case</h3>
<p>Outlier cases like this one (<span class="math inline">\(n = 10\)</span>):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>Set: [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>Model: Gaussian { μ: <span class="fl">0.1</span>, σ: <span class="fl">0.3</span> } (<span class="dv">10</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>Information Content: <span class="fl">5.0256952907839185</span> bits</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>Expected code length: <span class="dv">6</span> bits</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>Information Contributions (bits): [<span class="fl">0.17</span>, <span class="fl">0.17</span>, <span class="fl">0.17</span>, <span class="fl">0.17</span>, <span class="fl">0.17</span>, <span class="fl">0.17</span>, <span class="fl">0.17</span>, <span class="fl">0.17</span>, <span class="fl">0.17</span>, <span class="fl">3.45</span>]</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>Code: <span class="st">'1001110'</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>Code length: <span class="dv">7</span> bits</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>Analysis: <span class="op">+</span><span class="dv">1</span> bits (<span class="op">+</span><span class="fl">16.7</span><span class="op">%</span>) compared to expected</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>Decoding successful</span></code></pre></div>
<p>are generated between <span class="math inline">\(n = 1\)</span> and <span class="math inline">\(n = 100\)</span>, reproducing the plot from
an earlier section:</p>
<p><img src="res/gauss/outlierresults.svg" /></p>
<p>which is not optimal everywhere, but good enough.</p>
<h3 id="random-samples">Random Samples</h3>
<p>The error becomes less noticeable as we move to sets containing more
information. Here we sample <span class="math inline">\(n\)</span> elements from a
<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution"><strong>uniform</strong></a>
distribution between -5 and 5, once for each <span class="math inline">\(n\)</span>:</p>
<p><img src="res/gauss/randomuniform.svg" /></p>
<p>Seemingly identical performance is obtained when sampling from a
<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Normal_distribution"><strong>normal</strong></a>
distribution with the same variance <span class="math inline">\((\sigma^2 = \frac{10^2}{12} =
8.\overline{3})\)</span>:</p>
<p><img src="res/gauss/randomnormal.svg" /></p>
<p>Sampling from any wider distribution produces code lengths closer to the
information content than is visually distinguishable.</p>
  </section>
  <footer>
    <a href="./">Return</a>
  </footer>
</article>

    </main>

  </body>
</html>
